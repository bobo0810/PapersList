## 主干网络

### GhostNets on Heterogeneous Devices via Cheap Operations

| 主题 | 描述                                                         |
| ---- | :----------------------------------------------------------- |
| 问题 | 问题1：深度卷积、通道打乱等复杂操作在GPU下并行度不高，造成耗时。<br>问题2：观察到stage级别内部特征存在冗余。 |
| 解决 | 问题1：仅采用普通卷积，加速GPU并行<br/>问题2：在stage级别应用Ghost形式，用"便宜操作"生成冗余特征。 |
| 实现 | C-Ghost:  卷积级别，以代替原来的一个普通卷积 <br/>G-Ghost:  stage级别，以代替原来的一个stage网络结构<br>[原作知乎解读](https://zhuanlan.zhihu.com/p/540547718) |

### HS-ResNet: Hierarchical-Split Block on Convolutional Neural Network

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 视觉任务重，多尺度特征极其重要。三个目标如下：<br/>（1）减少特征图的冗余信息（2） 避免复杂计算下提高特征表达能力（3）保持速度和精度 |
| 创新点 | 提出HS-Block(Hierarchical-Split)，并构建HS-ResNet。          |
| 原理   | 1. 将ResNet-Bottleneck的Conv3x3替换为HS-Block，其包含众多通道级别Split和Concat（维护特征表达   sum破坏特征表达）。 <br>2. HS-Block将特征图分为S组，每组卷积拆分两份，一份恒等映射，一份接入下一组卷积捕获更精细特征。 <br/>3. 引入超参 分组数S：S越大，多尺度能力越强，速度相应变慢。 <br>4. 影响速度的两个因素：（1）特征图串行处理 （2）Split操作耗时 |
| 好处   | 同一层融合多尺度特征（类似Res2Net）                          |

### TARGETDROP: A TARGETED REGULARIZATION METHOD FOR CONVOLUTIONAL NEURAL NETWORKS

|  主题  | 描述                                                         |
| :----: | ------------------------------------------------------------ |
|  问题  | Dropout随机丢弃特征：由于空间相关特征允许丢弃信息在网络内流动，故对网络影响较小。 |
| 创新点 | 提出正则化TargetDrop，基于注意力机制针对性删除判别特征，迫使网络学习更多可区分特征。 |
|  原理  | 1. 通过通道注意力SE模块 提取 重要程度较大的特征图。 <br/>2.对于提取的特征图，以图中最高激活值为中心生成矩形块，以屏蔽高响应区域。 |
|  好处  | 训练启用，预测关闭。通用性强。                               |

### TARGETDROP: A TARGETED REGULARIZATION METHOD FOR CONVOLUTIONAL NEURAL NETWORKS

WACV2021

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 当前未关注过多尺度通道注意力融合。                           |
| 创新点 | 1. 统一特征融合方式，包括 同一层、短连接、长连接的sum/concat操作。<br/>2. 单特征通道加权：提出MS-CAM 多尺度通道注意力模块，纠正不同尺度的特征不一致，作用类似SE模块。<br/>3. 多特征融合：提出AFF、iAFF，解决初始特征聚合的问题。 |
| 原理   | 1.通过结合通道注意力和空间注意力，以融合特征。<br/>2. 由于初始聚合特征影响最终特征，iAFF用迭代方式缓解。 |
| 好处   | 即插即用，统一特征融合方式。                                 |

### SplitNet: Divide and Co-training

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 随着宽度增长，网络性能没有线性提升且很快饱和。               |
| 创新点 | 1. 提出构建网络新维度：增加网络数量，而非缩放网络宽度。<br/>2. 由于可分离性，小网络并行度更高，速度比大网络更快。 |
| 原理   | 1. SplitNet：将大网络拆分为数个小网络，且每个小网络具有大网络部分参数。<br/>2. 协同训练小网络，以相同数据的不同视角（即不同增广方式）学习不同和互补的知识。 |
| 好处   | 集成小网络的性能优于大网络，且速度更快。                     |

### Domain-transferred Face Augmentation Network

ACCV2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 数据集缺乏类内多样性（不同姿态、亮度等）                     |
| 创新点 | 1. 提出基于3D建模辅助的域迁移人脸增广网络DotFAN。通过知识蒸馏，基于公开的丰富人脸数据集进行域迁移，生成一系列增广图像。<br/>2.首次提出 域迁移人脸增广策略，将丰富域的知识迁移到目标域，同时保存身份识别信息。<br/>3. 丰富类内多样性、人脸正面化以提高可用性。 |
| 原理   | 1. DotFAN包含两个额外子网络，即FEM人脸专业建模、FSR人脸形状回归。<br/>2.FEM在公开的丰富数据集预训练，用于捕获人脸身份信息；FSR用于提取人脸属性。<br/>3. DotFAN能够分别学习 人脸特征编码，并有效生成人脸图像（即包含丰富人脸属性，同时保持增广人脸的身份信息不变） |
| 好处   | 增广类内样本，扩充数据集。                                   |

### FAN: Feature Adaptation Network for Surveillance Face Recognition and Normalization

ACCV2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 监控场景的低分辨率人脸识别困难。                             |
| 创新点 | 1. 提出特征适应网络FAN，以解决监控人脸识别和 规范化（成对或非成对均适用）<br/>2. 将特征分解为身份特征和非身份特征，同时实现视觉人脸规范化和保护身份信息。<br/>3. 在FAN中提出随机尺度增广，解决监控下未知分辨率图像。 |
| 原理   | 1. 输入监控图像，学习针对人脸识别的鲁棒性身份特征，特征生成 规范化人脸（加强面部细节和自然的姿态亮度等) <br/>2. 与超像素不同，本文的人脸规范化 无需像素级别的样本对。 |
| 好处   | 针对监控图像的人脸识别。                                     |

### GroupFace: Learning Latent Groups and Constructing Group-based Representations for Face Recognition

CVPR2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 1.  低维特征较难区分百万人脸图像。<br/>2.  单分支网络无法充分编码信息，且主干网络未针对人脸识别设计。 |
| 创新点 | 1.  提出自适应分组结构，学习多种潜在分组，提供自适应分布的组标签。<br/>2.  提出GroupFace，聚合实例特征和组级特征，加强特征表达质量。<br/>3.  提出新的相似度指标，以利用额外的分组信息。 |
| 原理   | 1.  常规分支学习实例特征，多分支学习组级特征。<br/>2.  组确定网络GDN 通过实例特征对组级特征进行额外监督。<br/>3.  总损失由人脸识别损失和分组损失组成。 |
| 好处   | 1. 为分组稳定，需加载预训练权重再训练。<br/>2. 加强特征表达，通用性强。 |



## 轻量级网络

### ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 移动设备资源受限，逐点卷积Conv1x1复杂度高。                  |
| 创新点 | 1. 提出“逐点组卷积”和“通道打乱”，减少计算量且保持精度。<br/>（1）"逐点组卷积" 减少1x1卷积的计算复杂度。<br/>（2） “通道打乱” 加强组间信息流动。<br/>2. 基于此提出ShuffleNet。 |
| 原理   | 1. 通道打乱：分组特征(g,n) -> 转置(n,g) ->  拉伸一维(n*g)  -> reshape(g,n)，其中g分组数,n每组通道数。<br/>2. 降采样时，采用Concat代替逐元素操作Add来扩充通道数。 |
| 好处   | 保持精度同时计算量大幅减少                                   |

### ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design

ECCV2018

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 针对计算复杂度，当前设计广泛参考间接指标乘加操作数FLOPs，而非速度、延迟等直接指标 |
| 创新点 | 1.  提出设计准则<br/>	（1）通道数不变，可最小化内存访问成本MAC <br/>	（2）分组卷积的组数 增加MAC<br/>	（3）网络结构减少并行度<br/>	（4）逐元素操作 FLOPs小，但MAC较大<br/>2.  基于准则，提出ShuffleNet V2 |
| 原理   | 1. 间接指标FLOPs与直接指标速度的两点差异：<br/>  （1）内存访问成本MAC  （2）并行度<br/>2. 尺度不变时：通道拆分，通道打乱，弃用分组卷积，输出通道不变。<br/>3. 尺度改变时：不拆分，通道打乱，弃用分组卷积，输出通道加倍。 |
| 好处   | 多快好省的轻量级网络                                         |

### GhostNet: More Features from Cheap Operations

CVPR2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 1.当前设计未考虑特征间的关系和冗余性。<br/>2.特征内部存在相似特征A-B-C..，即A是本质特征, B、C是A的鬼影特征。 |
| 创新点 | 提出Ghost模块，并构建GhostNet，用简单的线性操作提取更多的冗余特征。 |
| 原理   | 1. 首先用常规卷积生成 较少的m通道，再用s个线性操作扩充通道数，生成鬼影特征。<br/>2. 根据式4&5，FLOPs、参数量较原网络均下降s倍。<br/>3.  线性变换操作为卷积，可模拟平滑、模糊、运动等。 |
| 好处   | 多快好省，即插即用。                                         |

### Model Rubik’s Cube: Twisting Resolution, Depth and Width for TinyNets

NeurIPS2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 轻量网络中分辨率、深度、宽度三个维度并非同等重要。           |
| 创新点 | 1. 首次探索轻量网络三个维度的重要程度，即分辨率r >深度d >宽度w。<br/>2. 通过扭曲分辨率r、宽度w、深度d，用扭曲公式生成TinyNets，性能更好、更轻量。 |
| 原理   | 1. 以EfficientNet-B0为基础，先对r、w、d随机采样，生成大量模型并训练。<br/>2. 基于实验结果，训练高斯过程回归模型确定分辨率r和深度d。<br/>3. 基于FLOPs、r、d，确定宽度w。 |
| 好处   | 在FLOPs限制下，用更少成本实现更高性能。                      |


## 激活函数

### Funnel Activation for Visual Recognition

ECCV2020	

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 当前激活函数没有专为视觉任务设计，激活过程中的空间不敏感性阻碍识别。 |
| 创新点 | 提出FReLU，将ReLU扩展到二维<br/>（1）像素级别建模（2）通过规则卷积捕获视觉布局（3）将感受野引入非线性激活层 |
| 原理   | 用卷积操作替代ReLU的下限0。                                  |
| 好处   | 简单高效且易于迁移各种视觉任务。                             |

### Dynamic ReLU

ECCV2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 当前ReLU及变种都是固定参数，对所有输入执行相同操作。         |
| 创新点 | 1. 提出动态Dy-ReLU，通过汇总空间及通道维度信息去自适应激活函数。<br/>2.  统一现有的多数激活函数。 |
| 原理   | Dy-ReLU将全局信息编码为超函数，并相应调整分段线性激活函数，以增强表达能力。 |
| 好处   | 即插即用，统一多数激活函数。                                 |