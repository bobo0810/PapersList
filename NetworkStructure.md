## 网络结构

### HS-ResNet: Hierarchical-Split Block on Convolutional Neural Network

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 视觉任务重，多尺度特征极其重要。三个目标如下：<br/>（1）减少特征图的冗余信息（2） 避免复杂计算下提高特征表达能力（3）保持速度和精度 |
| 创新点 | 提出HS-Block(Hierarchical-Split)，并构建HS-ResNet。          |
| 原理   | 1. 将ResNet-Bottleneck的Conv3x3替换为HS-Block，其包含众多通道级别Split和Concat（维护特征表达   sum破坏特征表达）。 <br>2. HS-Block将特征图分为S组，每组卷积拆分两份，一份恒等映射，一份接入下一组卷积捕获更精细特征。 <br/>3. 引入超参 分组数S：S越大，多尺度能力越强，速度相应变慢。 <br>4. 影响速度的两个因素：（1）特征图串行处理 （2）Split操作耗时 |
| 好处   | 同一层融合多尺度特征（类似Res2Net）                          |

### TARGETDROP: A TARGETED REGULARIZATION METHOD FOR CONVOLUTIONAL NEURAL NETWORKS

|  主题  | 描述                                                         |
| :----: | ------------------------------------------------------------ |
|  问题  | Dropout随机丢弃特征：由于空间相关特征允许丢弃信息在网络内流动，故对网络影响较小。 |
| 创新点 | 提出正则化TargetDrop，基于注意力机制针对性删除判别特征，迫使网络学习更多可区分特征。 |
|  原理  | 1. 通过通道注意力SE模块 提取 重要程度较大的特征图。 <br/>2.对于提取的特征图，以图中最高激活值为中心生成矩形块，以屏蔽高响应区域。 |
|  好处  | 训练启用，预测关闭。通用性强。                               |

### TARGETDROP: A TARGETED REGULARIZATION METHOD FOR CONVOLUTIONAL NEURAL NETWORKS

WACV2021

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 当前未关注过多尺度通道注意力融合。                           |
| 创新点 | 1. 统一特征融合方式，包括 同一层、短连接、长连接的sum/concat操作。<br/>2. 单特征通道加权：提出MS-CAM 多尺度通道注意力模块，纠正不同尺度的特征不一致，作用类似SE模块。<br/>3. 多特征融合：提出AFF、iAFF，解决初始特征聚合的问题。 |
| 原理   | 1.通过结合通道注意力和空间注意力，以融合特征。<br/>2. 由于初始聚合特征影响最终特征，iAFF用迭代方式缓解。 |
| 好处   | 即插即用，统一特征融合方式。                                 |

### SplitNet: Divide and Co-training

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 随着宽度增长，网络性能没有线性提升且很快饱和。               |
| 创新点 | 1. 提出构建网络新维度：增加网络数量，而非缩放网络宽度。<br/>2. 由于可分离性，小网络并行度更高，速度比大网络更快。 |
| 原理   | 1. SplitNet：将大网络拆分为数个小网络，且每个小网络具有大网络部分参数。<br/>2. 协同训练小网络，以相同数据的不同视角（即不同增广方式）学习不同和互补的知识。 |
| 好处   | 集成小网络的性能优于大网络，且速度更快。                     |

### Domain-transferred Face Augmentation Network

ACCV2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 数据集缺乏类内多样性（不同姿态、亮度等）                     |
| 创新点 | 1. 提出基于3D建模辅助的域迁移人脸增广网络DotFAN。通过知识蒸馏，基于公开的丰富人脸数据集进行域迁移，生成一系列增广图像。<br/>2.首次提出 域迁移人脸增广策略，将丰富域的知识迁移到目标域，同时保存身份识别信息。<br/>3. 丰富类内多样性、人脸正面化以提高可用性。 |
| 原理   | 1. DotFAN包含两个额外子网络，即FEM人脸专业建模、FSR人脸形状回归。<br/>2.FEM在公开的丰富数据集预训练，用于捕获人脸身份信息；FSR用于提取人脸属性。<br/>3. DotFAN能够分别学习 人脸特征编码，并有效生成人脸图像（即包含丰富人脸属性，同时保持增广人脸的身份信息不变） |
| 好处   | 增广类内样本，扩充数据集。                                   |

### FAN: Feature Adaptation Network for Surveillance Face Recognition and Normalization

ACCV2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 监控场景的低分辨率人脸识别困难。                             |
| 创新点 | 1. 提出特征适应网络FAN，以解决监控人脸识别和 规范化（成对或非成对均适用）<br/>2. 将特征分解为身份特征和非身份特征，同时实现视觉人脸规范化和保护身份信息。<br/>3. 在FAN中提出随机尺度增广，解决监控下未知分辨率图像。 |
| 原理   | 1. 输入监控图像，学习针对人脸识别的鲁棒性身份特征，特征生成 规范化人脸（加强面部细节和自然的姿态亮度等) <br/>2. 与超像素不同，本文的人脸规范化 无需像素级别的样本对。 |
| 好处   | 针对监控图像的人脸识别。                                     |

## 轻量级网络

- TODO





## 激活函数

### Funnel Activation for Visual Recognition

ECCV2020	

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 当前激活函数没有专为视觉任务设计，激活过程中的空间不敏感性阻碍识别。 |
| 创新点 | 提出FReLU，将ReLU扩展到二维<br/>（1）像素级别建模（2）通过规则卷积捕获视觉布局（3）将感受野引入非线性激活层 |
| 原理   | 用卷积操作替代ReLU的下限0。                                  |
| 好处   | 简单高效且易于迁移各种视觉任务。                             |

### Dynamic ReLU

ECCV2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 当前ReLU及变种都是固定参数，对所有输入执行相同操作。         |
| 创新点 | 1. 提出动态Dy-ReLU，通过汇总空间及通道维度信息去自适应激活函数。<br/>2.  统一现有的多数激活函数。 |
| 原理   | Dy-ReLU将全局信息编码为超函数，并相应调整分段线性激活函数，以增强表达能力。 |
| 好处   | 即插即用，统一多数激活函数。                                 |
