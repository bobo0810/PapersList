## 训练策略

### BroadFace: Looking at Tens of Thousands of People at Once for Face Recognition

ECCV2020

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 常规方法每次只取min-ibatch，无法反映 整个数据集分布。        |
| 创新点 | 提出BroadFace，在训练阶段增加实例的补偿方法，能够考虑到大量身份数据。 |
| 原理   | 1. 通过 当前类中心与过去类中心的差值，将 队列内过去特征 补偿近似为 当前特征。<br/>2. mini-batch的梯度更新卷积层，mini-batch和队列concat的梯度更新分类器。<br/>3. 更好的分类器训练出更好的卷积层。 |
| 好处   | 由于队列，故用于fintuning阶段。                              |

### Semi-Siamese Training for Shallow Face Learning

ECCV2020  

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 1. 每个类别id对应图像过少，仅包含注册照和生活照两张，称为浅层人脸学习。<br/>2. 缺乏类内多样性，导致特征维度崩溃、网络极易退化或过拟合。 |
| 创新点 | 1. 提出Semi-Siamese Training (SST)训练策略，采用两个孪生网络，两者结构相同，参数接近但不同，保证类内差异。<br/>2. 第一个网络提取注册集特征作为类中心，抛弃分类器；第二个网络提取生活照训练分类层。 |
| 原理   | 1. 正确更新Wy和Xi：损失更新探测集网络，滑动平均更新注册集网络。SGD更新一个网络，用滑动均值更新另一个。<br/>2. 保持Wy的项远离0：用注册集网络的输出代替类中心权重。 |
| 好处   | 浅层人脸学习是痛点，但所提方法未像BroadFace进行特征补偿，效果存疑。 |

### Partial FC: Training 10 Million Identities on a Single Machine

AAAI2021

| 主题   | 描述                                                         |
| ------ | :----------------------------------------------------------- |
| 问题   | 1. 类别过多，导致分类器GPU占用过大 ，故采用模型并行。<br/>2. 当类别持续增大（亿级），模型并行时单个GPU占用也持续增大，导致无法训练更大规模id分类。 |
| 创新点 | 1. 提出大规模id分类的训练策略,成功训练亿级目标。<br/>2. 提出softmax近似算法，仅用10%类中心仍保持准确率。<br/>3. 提供Glint360K数据集 |
| 原理   | 提出softmax近似算法，用PPRN（正类全采样，负类随机采10%）来近似softmax。 |
| 好处   | 解决“能否”训练亿级类别问题，并非持续提升。                   |